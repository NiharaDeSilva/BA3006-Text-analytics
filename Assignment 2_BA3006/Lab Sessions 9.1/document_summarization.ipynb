{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created July 2017\n",
    "\n",
    "@author: arw\n",
    "\"\"\"\n",
    "\n",
    "from normalization import normalize_corpus, parse_document\n",
    "from utils import build_feature_matrix, low_rank_svd\n",
    "import numpy as np\n",
    "\n",
    "# We simulate a toy 'document collection' as follows\n",
    "toy_text = \"\"\"\n",
    "Elephants are large mammals of the family Elephantidae \n",
    "and the order Proboscidea. Two species are traditionally recognised, \n",
    "the African elephant and the Asian elephant. Elephants are scattered \n",
    "throughout sub-Saharan Africa, South Asia, and Southeast Asia. Male \n",
    "African elephants are the largest extant terrestrial animals. All \n",
    "elephants have a long trunk used for many purposes, \n",
    "particularly breathing, lifting water and grasping objects. Their \n",
    "incisors grow into tusks, which can serve as weapons and as tools \n",
    "for moving objects and digging. Elephants' large ear flaps help \n",
    "to control their body temperature. Their pillar-like legs can \n",
    "carry their great weight. African elephants have larger ears \n",
    "and concave backs while Asian elephants have smaller ears \n",
    "and convex or level backs.  \n",
    "\"\"\"\n",
    "\n",
    "# We define a function to calculate the summarization ratio - with default 0.5\n",
    "from gensim.summarization import summarize\n",
    "\n",
    "# gensim uses the popular TextRank algorithm to produce its summaries\n",
    "def text_summarization_gensim(text, summary_ratio=0.5):\n",
    "    \n",
    "    summary = summarize(text, split=True, ratio=summary_ratio)\n",
    "    for sentence in summary:\n",
    "        print(sentence)\n",
    "\n",
    "# Parse the document using code in our normalization.py module\n",
    "docs = parse_document(toy_text)\n",
    "text = ' '.join(docs) # 'flatten' the 'corpus' into a singe long string\n",
    "text_summarization_gensim(text, summary_ratio=0.4) # get a summary which is a little less than half the original\n",
    "\n",
    "\n",
    "\n",
    "# We will now try to build our own summarization algorithm\n",
    "# First we check the data we have   \n",
    "sentences = parse_document(toy_text)\n",
    "norm_sentences = normalize_corpus(sentences,lemmatize=False) \n",
    "total_sentences = len(norm_sentences)\n",
    "print('Total Sentences in Document:', total_sentences)  \n",
    "\n",
    "# For LSA, we need to first define the # of sentences we want (n) and the # of topics (k)\n",
    "num_sentences = 3\n",
    "num_topics = 2\n",
    "\n",
    "# We call our utility function to build a feature matrix using CountVectorizer and TfidfVectorizer\n",
    "# Here we use the bag of words features by passing the parameter 'frequency' - what are the other options?\n",
    "vec, dt_matrix = build_feature_matrix(sentences, \n",
    "                                      feature_type='frequency')\n",
    "# We need to fist transpose our document-term matrix to a term-document matrix\n",
    "td_matrix = dt_matrix.transpose()\n",
    "td_matrix = td_matrix.multiply(td_matrix > 0)\n",
    "\n",
    "# We need to get low rank SVD components from our utils module\n",
    "u, s, vt = low_rank_svd(td_matrix, singular_count=num_topics)  \n",
    "\n",
    "# We remove singular values that are lower than a heuristic threshold - here 0.5                                       \n",
    "sv_threshold = 0.5\n",
    "min_sigma_value = max(s) * sv_threshold\n",
    "s[s < min_sigma_value] = 0\n",
    "\n",
    "# Compute salience scores for all sentences in document\n",
    "salience_scores = np.sqrt(np.dot(np.square(s), np.square(vt)))\n",
    "print(np.round(salience_scores, 2))\n",
    "\n",
    "# Rank sentences based on their salience scores\n",
    "top_sentence_indices = salience_scores.argsort()[-num_sentences:][::-1]\n",
    "top_sentence_indices.sort()\n",
    "\n",
    "# View the highest scoring sentence index positions\n",
    "print(top_sentence_indices)\n",
    "\n",
    "# Get the document summary by combining the above sentences\n",
    "# Compare the output with what gensim produces with its TextRank implementation\n",
    "for index in top_sentence_indices:\n",
    "    print(sentences[index])\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Putting all the above together, we can define a generic LSA based text summarizer as follows\n",
    "def lsa_text_summarizer(documents, num_sentences=2,\n",
    "                        num_topics=2, feature_type='frequency',\n",
    "                        sv_threshold=0.5):\n",
    "                            \n",
    "    vec, dt_matrix = build_feature_matrix(documents, \n",
    "                                          feature_type=feature_type)\n",
    "\n",
    "    td_matrix = dt_matrix.transpose()\n",
    "    td_matrix = td_matrix.multiply(td_matrix > 0)\n",
    "\n",
    "    u, s, vt = low_rank_svd(td_matrix, singular_count=num_topics)  \n",
    "    min_sigma_value = max(s) * sv_threshold\n",
    "    s[s < min_sigma_value] = 0\n",
    "    \n",
    "    salience_scores = np.sqrt(np.dot(np.square(s), np.square(vt)))\n",
    "    top_sentence_indices = salience_scores.argsort()[-num_sentences:][::-1]\n",
    "    top_sentence_indices.sort()\n",
    "    \n",
    "    for index in top_sentence_indices:\n",
    "        print(sentences[index])\n",
    "    \n",
    "    \n",
    "    \n",
    "# Sometimes, we want to be able to visualize our sentence 'graph'\n",
    "# For this, we can use the popular general purpose networkx package\n",
    "import networkx\n",
    "\n",
    "# Define number of sentences in final summary\n",
    "num_sentences = 3\n",
    "# Construct weighted document term matrix (using tfidf instead of frequencies as before)\n",
    "vec, dt_matrix = build_feature_matrix(norm_sentences, \n",
    "                                      feature_type='tfidf')\n",
    "\n",
    "# Construct the document similarity matrix\n",
    "similarity_matrix = (dt_matrix * dt_matrix.T)\n",
    "# View the document similarity matrix by making the sparse matric dense!\n",
    "print(np.round(similarity_matrix.todense(), 2))\n",
    "\n",
    "# We can now build a similarity graph using the networkx package\n",
    "similarity_graph = networkx.from_scipy_sparse_matrix(similarity_matrix)\n",
    "# View the network for this simple 9 sentence similarity graph\n",
    "networkx.draw_networkx(similarity_graph)\n",
    "\n",
    "\n",
    "# Now compute the pagerank scores for all the sentences\n",
    "scores = networkx.pagerank(similarity_graph)\n",
    "# Rank the sentences based on their scores\n",
    "ranked_sentences = sorted(((score, index) \n",
    "                            for index, score \n",
    "                            in scores.items()), \n",
    "                          reverse=True)\n",
    "# This is a list, so to view the structure we simply type it in the console\n",
    "ranked_sentences\n",
    "\n",
    "# Once again, we get the top sentence indices for our summary\n",
    "top_sentence_indices = [ranked_sentences[index][1] \n",
    "                        for index in range(num_sentences)]\n",
    "top_sentence_indices.sort()\n",
    "# We can view the top sentence indices\n",
    "print(top_sentence_indices)\n",
    "\n",
    "# And finally construct the document summary to output\n",
    "for index in top_sentence_indices:\n",
    "    print(sentences[index])\n",
    "    \n",
    "\n",
    "# Putting all the above together, we can define a generic TextRank based text summarizer as follows\n",
    "def textrank_text_summarizer(documents, num_sentences=2,\n",
    "                             feature_type='frequency'):\n",
    "    \n",
    "    vec, dt_matrix = build_feature_matrix(norm_sentences, \n",
    "                                      feature_type='tfidf')\n",
    "    similarity_matrix = (dt_matrix * dt_matrix.T)\n",
    "        \n",
    "    similarity_graph = networkx.from_scipy_sparse_matrix(similarity_matrix)\n",
    "    scores = networkx.pagerank(similarity_graph)   \n",
    "    \n",
    "    ranked_sentences = sorted(((score, index) \n",
    "                                for index, score \n",
    "                                in scores.items()), \n",
    "                              reverse=True)\n",
    "\n",
    "    top_sentence_indices = [ranked_sentences[index][1] \n",
    "                            for index in range(num_sentences)]\n",
    "    top_sentence_indices.sort()\n",
    "    \n",
    "    for index in top_sentence_indices:\n",
    "        print(sentences[index])                            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Now for a slightly more realistic summarization task\n",
    "# We use both the above summarizers by calling their reusable functions\n",
    "\n",
    "DOCUMENT = \"\"\"\n",
    "The Elder Scrolls V: Skyrim is an open world action role-playing video game \n",
    "developed by Bethesda Game Studios and published by Bethesda Softworks. \n",
    "It is the fifth installment in The Elder Scrolls series, following \n",
    "The Elder Scrolls IV: Oblivion. Skyrim's main story revolves around \n",
    "the player character and their effort to defeat Alduin the World-Eater, \n",
    "a dragon who is prophesied to destroy the world. \n",
    "The game is set two hundred years after the events of Oblivion \n",
    "and takes place in the fictional province of Skyrim. The player completes quests \n",
    "and develops the character by improving skills. \n",
    "Skyrim continues the open world tradition of its predecessors by allowing the \n",
    "player to travel anywhere in the game world at any time, and to \n",
    "ignore or postpone the main storyline indefinitely. The player may freely roam \n",
    "over the land of Skyrim, which is an open world environment consisting \n",
    "of wilderness expanses, dungeons, cities, towns, fortresses and villages. \n",
    "Players may navigate the game world more quickly by riding horses, \n",
    "or by utilizing a fast-travel system which allows them to warp to previously \n",
    "Players have the option to develop their character. At the beginning of the game, \n",
    "players create their character by selecting one of several races, \n",
    "including humans, orcs, elves and anthropomorphic cat or lizard-like creatures, \n",
    "and then customizing their character's appearance.discovered locations. Over the \n",
    "course of the game, players improve their character's skills, which are numerical \n",
    "representations of their ability in certain areas. There are eighteen skills \n",
    "divided evenly among the three schools of combat, magic, and stealth. \n",
    "Skyrim is the first entry in The Elder Scrolls to include Dragons in the game's \n",
    "wilderness. Like other creatures, Dragons are generated randomly in the world \n",
    "and will engage in combat. \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "sentences = parse_document(DOCUMENT)\n",
    "norm_sentences = normalize_corpus(sentences,lemmatize=True) \n",
    "print(\"Total Sentences:\", len(norm_sentences))\n",
    "\n",
    "lsa_text_summarizer(norm_sentences, num_sentences=3,\n",
    "                    num_topics=5, feature_type='frequency',\n",
    "                    sv_threshold=0.5)  \n",
    "\n",
    "textrank_text_summarizer(norm_sentences, num_sentences=3,\n",
    "                         feature_type='tfidf')\n",
    "\n",
    "# Compare the outputs of the two algorithms\n",
    "# Also compare this with gensim's built-in algorithm based on TextRank\n",
    "# What can you observe?\n",
    "# Try this on a larger document collection and compare results\n",
    "\n",
    "# SAQ: Try to use different summarization ratios and number of topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
