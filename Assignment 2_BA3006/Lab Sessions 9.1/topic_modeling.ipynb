{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dog': 0, 'fox': 1, 'jump': 2, 'clever': 3, 'quick': 4, 'lazy': 5, 'slow': 6, 'cat': 7, 'smarter': 8, 'excellent': 9, 'language': 10, 'programming': 11, 'python': 12, 'java': 13, 'ruby': 14, 'popular': 15, 'program': 16, 'small': 17}\n",
      "Topic #1\n",
      "-0.459*\"language\" + -0.459*\"programming\" + -0.344*\"python\" + -0.344*\"java\" + -0.336*\"popular\" + -0.318*\"ruby\" + -0.318*\"excellent\" + -0.148*\"program\" + -0.074*\"small\" + -0.000*\"clever\"\n",
      "\n",
      "Topic #2\n",
      "0.459*\"dog\" + 0.459*\"fox\" + 0.444*\"jump\" + 0.322*\"cat\" + 0.322*\"smarter\" + 0.208*\"slow\" + 0.208*\"lazy\" + 0.208*\"clever\" + 0.208*\"quick\" + 0.000*\"program\"\n",
      "\n",
      "Topic #1 with weights\n",
      "[('language', -0.46), ('programming', -0.46), ('python', -0.34), ('java', -0.34), ('popular', -0.34)]\n",
      "\n",
      "Topic #2 with weights\n",
      "[('dog', 0.46), ('fox', 0.46), ('jump', 0.44), ('cat', 0.32), ('smarter', 0.32)]\n",
      "\n",
      "Topic #1 without weights\n",
      "['dog', 'fox', 'jump', 'smarter', 'cat', 'slow', 'lazy', 'quick', 'clever']\n",
      "\n",
      "Topic #2 without weights\n",
      "['programming', 'language', 'python', 'java', 'popular', 'excellent', 'ruby', 'program']\n",
      "\n",
      "Topic #1 with weights\n",
      "[('programming', 0.08), ('language', 0.07), ('program', 0.07), ('python', 0.06), ('quick', 0.06)]\n",
      "\n",
      "Topic #2 with weights\n",
      "[('dog', 0.08), ('fox', 0.07), ('smarter', 0.07), ('cat', 0.07), ('slow', 0.06)]\n",
      "\n",
      "Topic #1 with weights\n",
      "[('fox', 1.86), ('dog', 1.86), ('jump', 1.19), ('clever', 1.12), ('quick', 1.12), ('lazy', 1.12), ('slow', 1.12), ('cat', 1.06)]\n",
      "\n",
      "Topic #2 with weights\n",
      "[('programming', 1.8), ('language', 1.8), ('java', 1.64), ('python', 1.64), ('program', 1.3), ('ruby', 1.11), ('excellent', 1.11), ('popular', 1.06)]\n",
      "\n",
      "Topic #1 with weights\n",
      "[('programming', 0.55), ('language', 0.55), ('python', 0.4), ('java', 0.4), ('popular', 0.24), ('ruby', 0.23), ('excellent', 0.23), ('program', 0.09), ('small', 0.03)]\n",
      "\n",
      "Topic #2 with weights\n",
      "[('dog', 0.57), ('fox', 0.57), ('jump', 0.35), ('smarter', 0.26), ('cat', 0.26), ('quick', 0.13), ('slow', 0.13), ('clever', 0.13), ('lazy', 0.13)]\n",
      "\n",
      "I base the value of a game on the amount of enjoyable gameplay I can get out of it and this one was definitely worth the price!\n",
      "Topic #1 without weights\n",
      "['skyrim', 'one', 'like', 'quest', 'play', 'oblivion', 'go', 'get', 'time', 'good']\n",
      "\n",
      "Topic #2 without weights\n",
      "['recommend', 'love', 'ever', 'best', 'great', 'level', 'elder', 'scroll', 'fun', 'buy']\n",
      "\n",
      "Topic #3 without weights\n",
      "['recommend', 'fun', 'highly', 'love', 'ever', 'wonderful', 'elder', 'finish', 'scroll', 'best']\n",
      "\n",
      "Topic #4 without weights\n",
      "['fun', 'recommend', 'scroll', 'elder', 'highly', 'wonderful', 'graphic', 'series', 'buy', 'cool']\n",
      "\n",
      "Topic #5 without weights\n",
      "['fun', 'love', 'elder', 'scroll', 'highly', '5', 'dont', 'hundred', 'hour', 'gameplay']\n",
      "\n",
      "Topic #1 without weights\n",
      "['fun', 'one', 'want', 'like', 'play', 'love', 'skyrim', 'buy', 'excellent', 'save']\n",
      "\n",
      "Topic #2 without weights\n",
      "['play', 'fun', 'much', 'one', 'skyrim', 'many', 'finish', 'great', 'like', 'dragon']\n",
      "\n",
      "Topic #3 without weights\n",
      "['love', 'like', 'one', 'oblivion', 'skyrim', 'get', 'good', 'definitely', 'level', 'ever']\n",
      "\n",
      "Topic #4 without weights\n",
      "['quest', 'good', 'great', 'hour', 'go', 'scroll', 'play', 'elder', 'get', 'series']\n",
      "\n",
      "Topic #5 without weights\n",
      "['love', 'make', 'buy', 'quest', 'play', 'amazing', 'come', 'world', 'say', 'time']\n",
      "\n",
      "Topic #1 without weights\n",
      "['de', 'momento', 'pagar', 'tarjeta', 'futuras', 'para', 'skyrimseguridad', 'recomiendo', 'compras', 'responsabilidad']\n",
      "\n",
      "Topic #2 without weights\n",
      "['booklet', 'estatic', 'wonder4ful', 'electricity', 'stays', 'heat', 'trhats', 'amazingly', 'interfere', '12yr']\n",
      "\n",
      "Topic #3 without weights\n",
      "['estatic', 'booklet', 'wonder4ful', 'electricity', 'stays', 'heat', 'trhats', 'amazingly', 'interfere', '12yr']\n",
      "\n",
      "Topic #4 without weights\n",
      "['game', 'play', 'get', 'one', 'skyrim', 'great', 'like', 'time', 'quest', 'much']\n",
      "\n",
      "Topic #5 without weights\n",
      "['booklet', 'estatic', 'ask', 'disc', 'son', 'open', 'get', 'wonder4ful', 'electricity', 'stays']\n",
      "\n",
      "Topic #1 without weights\n",
      "['game', 'get', 'skyrim', 'play', 'time', 'quest', 'like', 'one', 'go', 'much']\n",
      "\n",
      "Topic #2 without weights\n",
      "['ever', 'best', 'game', 'play', 'rpg', 'one', 'hour', 'great', 'definitely', 'decade']\n",
      "\n",
      "Topic #3 without weights\n",
      "['scroll', 'elder', 'series', 'always', 'love', 'pass', 'buy', 'far', 'franchise', 'dont']\n",
      "\n",
      "Topic #4 without weights\n",
      "['game', 'recommend', 'love', 'great', 'highly', 'play', 'wonderful', 'like', 'would', 'graphic']\n",
      "\n",
      "Topic #5 without weights\n",
      "['fun', 'game', 'much', 'graphic', 'improvement', 'expect', 'mission', 'see', 'hour', 'couple']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created July 2017\n",
    "\n",
    "@author: arw\n",
    "\"\"\"\n",
    "\n",
    "from gensim import corpora, models\n",
    "from normalization import normalize_corpus\n",
    "import numpy as np\n",
    "\n",
    "toy_corpus = [\"The fox jumps over the dog\",\n",
    "\"The fox is very clever and quick\",\n",
    "\"The dog is slow and lazy\",\n",
    "\"The cat is smarter than the fox and the dog\",\n",
    "\"Python is an excellent programming language\",\n",
    "\"Java and Ruby are other programming languages\",\n",
    "\"Python and Java are very popular programming languages\",\n",
    "\"Python programs are smaller than Java programs\"]\n",
    "\n",
    "# LSI topic model\n",
    "norm_tokenized_corpus = normalize_corpus(toy_corpus, tokenize=True)\n",
    "norm_tokenized_corpus\n",
    "\n",
    "dictionary = corpora.Dictionary(norm_tokenized_corpus)\n",
    "print(dictionary.token2id)\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in norm_tokenized_corpus]\n",
    "corpus\n",
    "\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "\n",
    "total_topics = 2\n",
    "\n",
    "lsi = models.LsiModel(corpus_tfidf, \n",
    "                      id2word=dictionary, \n",
    "                      num_topics=total_topics)\n",
    "                      \n",
    "for index, topic in lsi.print_topics(total_topics):\n",
    "    print('Topic #'+str(index+1))\n",
    "    print(topic)\n",
    "    print()       \n",
    "    \n",
    "\n",
    "def print_topics_gensim(topic_model, total_topics=1,\n",
    "                        weight_threshold=0.0001,\n",
    "                        display_weights=False,\n",
    "                        num_terms=None):\n",
    "    \n",
    "    for index in range(total_topics):\n",
    "        topic = topic_model.show_topic(index)\n",
    "        topic = [(word, round(wt,2)) \n",
    "                 for word, wt in topic \n",
    "                 if abs(wt) >= weight_threshold]\n",
    "        if display_weights:\n",
    "            print('Topic #'+str(index+1)+' with weights')\n",
    "            print(topic[:num_terms] if num_terms else topic)\n",
    "        else:\n",
    "            print('Topic #'+str(index+1)+' without weights')\n",
    "            tw = [term for term, wt in topic]\n",
    "            print(tw[:num_terms] if num_terms else tw)\n",
    "        print()\n",
    "    \n",
    "\n",
    "print_topics_gensim(topic_model=lsi,\n",
    "                    total_topics=total_topics,\n",
    "                    num_terms=5,\n",
    "                    display_weights=True)\n",
    "\n",
    "    \n",
    "# LSI custom built topic model    \n",
    "from utils import build_feature_matrix, low_rank_svd\n",
    "\n",
    "norm_corpus = normalize_corpus(toy_corpus)\n",
    "\n",
    "vectorizer, tfidf_matrix = build_feature_matrix(norm_corpus, \n",
    "                                    feature_type='tfidf')\n",
    "td_matrix = tfidf_matrix.transpose()\n",
    "                              \n",
    "td_matrix = td_matrix.multiply(td_matrix > 0)\n",
    "\n",
    "total_topics = 2\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "u, s, vt = low_rank_svd(td_matrix, singular_count=total_topics)\n",
    "weights = u.transpose() * s[:, None]\n",
    "\n",
    "def get_topics_terms_weights(weights, feature_names):\n",
    "    feature_names = np.array(feature_names)\n",
    "    sorted_indices = np.array([list(row[::-1]) \n",
    "                           for row \n",
    "                           in np.argsort(np.abs(weights))])\n",
    "    sorted_weights = np.array([list(wt[index]) \n",
    "                               for wt, index \n",
    "                               in zip(weights,sorted_indices)])\n",
    "    sorted_terms = np.array([list(feature_names[row]) \n",
    "                             for row \n",
    "                             in sorted_indices])\n",
    "    \n",
    "    topics = [np.vstack((terms.T, \n",
    "                     term_weights.T)).T \n",
    "              for terms, term_weights \n",
    "              in zip(sorted_terms, sorted_weights)]     \n",
    "    \n",
    "    return topics            \n",
    "  \n",
    "                       \n",
    "def print_topics_udf(topics, total_topics=1,\n",
    "                     weight_threshold=0.0001,\n",
    "                     display_weights=False,\n",
    "                     num_terms=None):\n",
    "    \n",
    "    for index in range(total_topics):\n",
    "        topic = topics[index]\n",
    "        topic = [(term, float(wt))\n",
    "                 for term, wt in topic]\n",
    "        topic = [(word, round(wt,2)) \n",
    "                 for word, wt in topic \n",
    "                 if abs(wt) >= weight_threshold]\n",
    "                     \n",
    "        if display_weights:\n",
    "            print('Topic #'+str(index+1)+' with weights')\n",
    "            print(topic[:num_terms] if num_terms else topic)\n",
    "        else:\n",
    "            print('Topic #'+str(index+1)+' without weights')\n",
    "            tw = [term for term, wt in topic]\n",
    "            print(tw[:num_terms] if num_terms else tw)\n",
    "        print()\n",
    "\n",
    "topics = get_topics_terms_weights(weights, feature_names)        \n",
    "\n",
    "print_topics_udf(topics=topics,\n",
    "                 total_topics=total_topics,\n",
    "                 weight_threshold=0.15,\n",
    "                 display_weights=False)\n",
    "\n",
    "def train_lsi_model_gensim(corpus, total_topics=2):\n",
    "    \n",
    "    norm_tokenized_corpus = normalize_corpus(corpus, tokenize=True)\n",
    "    dictionary = corpora.Dictionary(norm_tokenized_corpus)\n",
    "    mapped_corpus = [dictionary.doc2bow(text) \n",
    "                     for text in norm_tokenized_corpus]\n",
    "    tfidf = models.TfidfModel(mapped_corpus)\n",
    "    corpus_tfidf = tfidf[mapped_corpus]\n",
    "    lsi = models.LsiModel(corpus_tfidf, \n",
    "                          id2word=dictionary,\n",
    "                          num_topics=total_topics)\n",
    "    return lsi\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_lda_model_gensim(corpus, total_topics=2):\n",
    "    \n",
    "    norm_tokenized_corpus = normalize_corpus(corpus, tokenize=True)\n",
    "    dictionary = corpora.Dictionary(norm_tokenized_corpus)\n",
    "    mapped_corpus = [dictionary.doc2bow(text) \n",
    "                     for text in norm_tokenized_corpus]\n",
    "    tfidf = models.TfidfModel(mapped_corpus)\n",
    "    corpus_tfidf = tfidf[mapped_corpus]\n",
    "    lda = models.LdaModel(corpus_tfidf, \n",
    "                          id2word=dictionary,\n",
    "                          iterations=1000,\n",
    "                          num_topics=total_topics)\n",
    "    return lda                     \n",
    "\n",
    "\n",
    "\n",
    "lda_gensim = train_lda_model_gensim(toy_corpus,\n",
    "                                    total_topics=2)\n",
    "                                    \n",
    "print_topics_gensim(topic_model=lda_gensim,\n",
    "                    total_topics=2,\n",
    "                    num_terms=5,\n",
    "                    display_weights=True)                                    \n",
    "\n",
    "                     \n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "norm_corpus = normalize_corpus(toy_corpus)\n",
    "vectorizer, tfidf_matrix = build_feature_matrix(norm_corpus, \n",
    "                                    feature_type='tfidf')                     \n",
    "total_topics = 2\n",
    "lda = LatentDirichletAllocation(n_components=total_topics, \n",
    "                                max_iter=1000,\n",
    "                                learning_method='online', \n",
    "                                learning_offset=50.,\n",
    "                                random_state=42)\n",
    "lda.fit(tfidf_matrix)\n",
    "\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "weights = lda.components_\n",
    "\n",
    "topics = get_topics_terms_weights(weights, feature_names)\n",
    "print_topics_udf(topics=topics,\n",
    "                 total_topics=total_topics,\n",
    "                 num_terms=8,\n",
    "                 display_weights=True)\n",
    "                 \n",
    "                 \n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "norm_corpus = normalize_corpus(toy_corpus)\n",
    "vectorizer, tfidf_matrix = build_feature_matrix(norm_corpus, \n",
    "                                    feature_type='tfidf')                     \n",
    "total_topics = 2\n",
    "nmf = NMF(n_components=total_topics, \n",
    "          random_state=42, alpha=.1, l1_ratio=.5)\n",
    "nmf.fit(tfidf_matrix)      \n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "weights = nmf.components_\n",
    "\n",
    "topics = get_topics_terms_weights(weights, feature_names)\n",
    "print_topics_udf(topics=topics,\n",
    "                 total_topics=total_topics,\n",
    "                 num_terms=None,\n",
    "                 display_weights=True)   \n",
    "\n",
    "\n",
    "\n",
    "# We now turn to a REAL problem\n",
    "                 \n",
    "import pandas as pd\n",
    "                 \n",
    "CORPUS = pd.read_csv('amazon_skyrim_reviews.csv')                     \n",
    "CORPUS = np.array(CORPUS['Reviews'])\n",
    "\n",
    "# view sample review\n",
    "print(CORPUS[12])\n",
    "\n",
    "        \n",
    "total_topics = 5\n",
    "        \n",
    "lsi_gensim = train_lsi_model_gensim(CORPUS,\n",
    "                                    total_topics=total_topics)\n",
    "print_topics_gensim(topic_model=lsi_gensim,\n",
    "                    total_topics=total_topics,\n",
    "                    num_terms=10,\n",
    "                    display_weights=False) \n",
    "\n",
    "\n",
    "lda_gensim = train_lda_model_gensim(CORPUS,\n",
    "                                    total_topics=total_topics)\n",
    "print_topics_gensim(topic_model=lda_gensim,\n",
    "                    total_topics=total_topics,\n",
    "                    num_terms=10,\n",
    "                    display_weights=False) \n",
    "\n",
    "\n",
    "norm_corpus = normalize_corpus(CORPUS)\n",
    "vectorizer, tfidf_matrix = build_feature_matrix(norm_corpus, \n",
    "                                    feature_type='tfidf') \n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=total_topics, \n",
    "                                max_iter=1000,\n",
    "                                learning_method='online', \n",
    "                                learning_offset=10.,\n",
    "                                random_state=42)\n",
    "lda.fit(tfidf_matrix)\n",
    "weights = lda.components_\n",
    "topics = get_topics_terms_weights(weights, feature_names)\n",
    "print_topics_udf(topics=topics,\n",
    "                 total_topics=total_topics,\n",
    "                 num_terms=10,\n",
    "                 display_weights=False)\n",
    "\n",
    "\n",
    "nmf = NMF(n_components=total_topics, \n",
    "          random_state=42, alpha=.1, l1_ratio=.5)\n",
    "nmf.fit(tfidf_matrix)      \n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "weights = nmf.components_\n",
    "\n",
    "topics = get_topics_terms_weights(weights, feature_names)\n",
    "print_topics_udf(topics=topics,\n",
    "                 total_topics=total_topics,\n",
    "                 num_terms=10,\n",
    "                 display_weights=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
