{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.cross_validation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e5ca28270bc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# So, this will be a 20-class classification problem!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfetch_20newsgroups\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# We need to remove headers of email since they won't help us in classification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.cross_validation'"
     ]
    }
   ],
   "source": [
    "# Dataset comprises of 20k newsposts in 20 different newsgroups - what topics are they on?\n",
    "# So, this will be a 20-class classification problem!\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# We need to remove headers of email since they won't help us in classification\n",
    "def get_data():\n",
    "    data = fetch_20newsgroups(subset='all',\n",
    "                              shuffle=True,\n",
    "                              remove=('headers', 'footers', 'quotes'))\n",
    "    return data\n",
    "    \n",
    "# Divide the data into training and testing sets\n",
    "def prepare_datasets(corpus, labels, test_data_proportion=0.3):\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(corpus, labels, \n",
    "                                                        test_size=0.33, random_state=42)\n",
    "    return train_X, test_X, train_Y, test_Y\n",
    "\n",
    "# We also remove empty documents since they would just add noise\n",
    "def remove_empty_docs(corpus, labels):\n",
    "    filtered_corpus = []\n",
    "    filtered_labels = []\n",
    "    for doc, label in zip(corpus, labels):\n",
    "        if doc.strip():\n",
    "            filtered_corpus.append(doc)\n",
    "            filtered_labels.append(label)\n",
    "\n",
    "    return filtered_corpus, filtered_labels\n",
    "    \n",
    "    \n",
    "dataset = get_data()\n",
    "\n",
    "print(dataset.target_names)\n",
    "\n",
    "corpus, labels = dataset.data, dataset.target\n",
    "corpus, labels = remove_empty_docs(corpus, labels)\n",
    "\n",
    "# Display an example newsgroup posting\n",
    "print('Sample document:', corpus[10])\n",
    "print('Class label:',labels[10])\n",
    "print('Actual class label:', dataset.target_names[labels[10]])\n",
    "\n",
    "train_corpus, test_corpus, train_labels, test_labels = prepare_datasets(corpus,\n",
    "                                                                        labels,\n",
    "                                                                        test_data_proportion=0.3)\n",
    "\n",
    "# First normalize both the training and test data using our previous funcionts                                                                        \n",
    "from normalization import normalize_corpus\n",
    "\n",
    "norm_train_corpus = normalize_corpus(train_corpus)\n",
    "norm_test_corpus = normalize_corpus(test_corpus)  \n",
    "\n",
    "''.strip()\n",
    "\n",
    "# Extract features using the extractors we defined\n",
    "from feature_extractors import bow_extractor, tfidf_extractor\n",
    "from feature_extractors import averaged_word_vectorizer\n",
    "from feature_extractors import tfidf_weighted_averaged_word_vectorizer\n",
    "import nltk\n",
    "import gensim\n",
    "\n",
    "# Bag of words (BoW) features\n",
    "bow_vectorizer, bow_train_features = bow_extractor(norm_train_corpus)  \n",
    "bow_test_features = bow_vectorizer.transform(norm_test_corpus) \n",
    "\n",
    "# TFIDF features\n",
    "tfidf_vectorizer, tfidf_train_features = tfidf_extractor(norm_train_corpus)  \n",
    "tfidf_test_features = tfidf_vectorizer.transform(norm_test_corpus)    \n",
    "\n",
    "\n",
    "# tokenize documents\n",
    "tokenized_train = [nltk.word_tokenize(text)\n",
    "                   for text in norm_train_corpus]\n",
    "tokenized_test = [nltk.word_tokenize(text)\n",
    "                   for text in norm_test_corpus]  \n",
    "# build word2vec model                   \n",
    "model = gensim.models.Word2Vec(tokenized_train,\n",
    "                               size=500,\n",
    "                               window=100,\n",
    "                               min_count=30,\n",
    "                               sample=1e-3)                  \n",
    "                   \n",
    "# averaged word vector features\n",
    "avg_wv_train_features = averaged_word_vectorizer(corpus=tokenized_train,\n",
    "                                                 model=model.wv,\n",
    "                                                 num_features=500)                   \n",
    "avg_wv_test_features = averaged_word_vectorizer(corpus=tokenized_test,\n",
    "                                                model=model.wv,\n",
    "                                                num_features=500)                                                 \n",
    "                   \n",
    "\n",
    "\n",
    "# tfidf weighted averaged word vector features\n",
    "vocab = tfidf_vectorizer.vocabulary_\n",
    "tfidf_wv_train_features = tfidf_weighted_averaged_word_vectorizer(corpus=tokenized_train, \n",
    "                                                                  tfidf_vectors=tfidf_train_features, \n",
    "                                                                  tfidf_vocabulary=vocab, \n",
    "                                                                  model=model, \n",
    "                                                                  num_features=500)\n",
    "tfidf_wv_test_features = tfidf_weighted_averaged_word_vectorizer(corpus=tokenized_test, \n",
    "                                                                 tfidf_vectors=tfidf_test_features, \n",
    "                                                                 tfidf_vocabulary=vocab, \n",
    "                                                                 model=model, \n",
    "                                                                 num_features=500)\n",
    "\n",
    "\n",
    "# Use sklearn's metrics function for evaluation of classifiers\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "# Define function to calculate the 4 common mertics\n",
    "def get_metrics(true_labels, predicted_labels):\n",
    "    \n",
    "    print('Accuracy:', np.round(\n",
    "                        metrics.accuracy_score(true_labels, \n",
    "                                               predicted_labels),\n",
    "                        2))\n",
    "    print('Precision:', np.round(\n",
    "                        metrics.precision_score(true_labels, \n",
    "                                               predicted_labels,\n",
    "                                               average='weighted'),\n",
    "                        2))\n",
    "    print('Recall:', np.round(\n",
    "                        metrics.recall_score(true_labels, \n",
    "                                               predicted_labels,\n",
    "                                               average='weighted'),\n",
    "                        2))\n",
    "    print('F1 Score:', np.round(\n",
    "                        metrics.f1_score(true_labels, \n",
    "                                               predicted_labels,\n",
    "                                               average='weighted'),\n",
    "                        2))\n",
    "                        \n",
    "\n",
    "# Master function to call the above defined functions to perform the classification,\n",
    "# predict the results and evaluate predictions against the test data\n",
    "def train_predict_evaluate_model(classifier, \n",
    "                                 train_features, train_labels, \n",
    "                                 test_features, test_labels):\n",
    "    # build model    \n",
    "    classifier.fit(train_features, train_labels)\n",
    "    # predict using model\n",
    "    predictions = classifier.predict(test_features) \n",
    "    # evaluate model prediction performance   \n",
    "    get_metrics(true_labels=test_labels, \n",
    "                predicted_labels=predictions)\n",
    "    return predictions    \n",
    "\n",
    "                        \n",
    "# Import the two classification algorithms we want to use for the task\n",
    "# Based on the features we extract, we altogether have 6 combinations of models to train               \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "svm = SGDClassifier(loss='hinge', n_iter=100)\n",
    "\n",
    "# Multinomial Naive Bayes with bag of words features\n",
    "mnb_bow_predictions = train_predict_evaluate_model(classifier=mnb,\n",
    "                                           train_features=bow_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=bow_test_features,\n",
    "                                           test_labels=test_labels)\n",
    "\n",
    "# Support Vector Machine with bag of words features\n",
    "svm_bow_predictions = train_predict_evaluate_model(classifier=svm,\n",
    "                                           train_features=bow_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=bow_test_features,\n",
    "                                           test_labels=test_labels)\n",
    "                                           \n",
    "# Multinomial Naive Bayes with tfidf features                                           \n",
    "mnb_tfidf_predictions = train_predict_evaluate_model(classifier=mnb,\n",
    "                                           train_features=tfidf_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=tfidf_test_features,\n",
    "                                           test_labels=test_labels)\n",
    "\n",
    "# Support Vector Machine with tfidf features\n",
    "svm_tfidf_predictions = train_predict_evaluate_model(classifier=svm,\n",
    "                                           train_features=tfidf_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=tfidf_test_features,\n",
    "                                           test_labels=test_labels)\n",
    "\n",
    "# Support Vector Machine with averaged word vector features\n",
    "svm_avgwv_predictions = train_predict_evaluate_model(classifier=svm,\n",
    "                                           train_features=avg_wv_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=avg_wv_test_features,\n",
    "                                           test_labels=test_labels)\n",
    "\n",
    "# Support Vector Machine with tfidf weighted averaged word vector features\n",
    "svm_tfidfwv_predictions = train_predict_evaluate_model(classifier=svm,\n",
    "                                           train_features=tfidf_wv_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=tfidf_wv_test_features,\n",
    "                                           test_labels=test_labels)\n",
    "\n",
    " \n",
    "# Confusion matrix for the tfidf-based SVM model (best in this case?)\n",
    "import pandas as pd\n",
    "cm = metrics.confusion_matrix(test_labels, svm_tfidf_predictions)\n",
    "pd.DataFrame(cm, index=range(0,20), columns=range(0,20))  \n",
    "\n",
    "class_names = dataset.target_names\n",
    "print(class_names[0], '->', class_names[15])\n",
    "print(class_names[18], '->', class_names[16]) \n",
    "print(class_names[19], '->', class_names[15]) \n",
    "\n",
    "\n",
    "\n",
    "# Checking the misclassified documents for error analysis\n",
    "import re\n",
    "\n",
    "num = 0\n",
    "for document, label, predicted_label in zip(test_corpus, test_labels, svm_tfidf_predictions):\n",
    "    if label == 0 and predicted_label == 15:\n",
    "        print('Actual Label:', class_names[label])\n",
    "        print('Predicted Label:', class_names[predicted_label])\n",
    "        print('Document:-')\n",
    "        print(re.sub('\\n', ' ', document))\n",
    "        print()\n",
    "        num += 1\n",
    "        if num == 4:\n",
    "            break\n",
    "\n",
    "\n",
    "num = 0\n",
    "for document, label, predicted_label in zip(test_corpus, test_labels, svm_tfidf_predictions):\n",
    "    if label == 18 and predicted_label == 16:\n",
    "        print('Actual Label:', class_names[label])\n",
    "        print('Predicted Label:', class_names[predicted_label])\n",
    "        print('Document:-')\n",
    "        print(re.sub('\\n', ' ', document))\n",
    "        print()\n",
    "        num += 1\n",
    "        if num == 4:\n",
    "            break\n",
    "\n",
    "# SAQ: Why are these misclassified? What can we do about it?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
